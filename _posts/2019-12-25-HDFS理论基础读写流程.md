layout: post
title: HDFS理论基础读写流程

------

分布式文件系统那么多

为什么hadoop项目中还要开发一个hdfs文件系统？



# 架构设计

- HDFS是一个主从（Master/Slave）架构
- 由一个NameNode和一些DataNode组成
- 面向文件包含：文件数据（data）和文件元数据（metadata）
- NameNode复杂存储和管理文件元数据，并维护一个层次型的文件目录树
- DataNode负责存储文件数据（block块），并提供block的读写
- DataNode与NameNode维持心跳，**并汇报自己持有的block信息**（在分布式情况下，更相信自己人，而不是依赖客户端提供的数据）
- Client和NameNode交互文件元数据和DataNode交互文件block数据

HDFS 维护了一个目录树结构

角色即JVM进程



# 角色功能

 ## NameNode

- 完全基于内存存储文件元数据、目录结构、文件block的映射（ps：1、基于内存存储，需要快速的对外提供服务；2、内存寻址的速度是磁盘IO的速度的10万倍）
- 需要持久化方案保证数据可靠性（内存存储掉电丢失数据，大小有限）
- 提供副本放置策略

## DataNode

- 基于本地磁盘存储block（文件形式）
- 并保存block的校验和数据保证block的可靠性
- 与NameNode保持心跳，汇报block列表状态



一般为了保证数据的一致性

日志：记录实时发生的增删改操作	

  完整性比较好

  加载恢复数据 ：慢、占空间

镜像、快照、dump、db、序列化

​	间隔（小时、天、10分钟、1分钟、5秒钟），内存全量数据基于某一个时间点做的向磁盘的溢写

​	恢复速度快过 日志文件

​	因为是间隔的，容易丢失一部分数据



HDFS：

​	Editslog：日志

​		体积小，记录少，必然有优势

​	FsImage： 镜像、快照

​		如果能更快的滚动更新时点

比如：现在10点

​	FsImage 9点 +9点到10点的增量的Editslog

1、加载FI

2、加载EL

3、内存就得到了关机前的全量

问题：

​	那么：FI时点是怎样滚动更新的？

​	由NN 8点溢写，9点溢写。。

​	NN：第一次开机的时候，只写一次FI，假设8点，到9点的时候，EL记录的是8~9点的日志，只需要将8~9点的日志的记录，更新到8点的FI中，FI的数据时点就变成了9点



知识点：

​	NN存元数据: 文件属性/么个块存在哪一个DN上

​		属性：/a/b/c.txt 32G  root:root rwxrwxrwx

​			blk01 node01   node03 ( 不存)

​			bll03  node02   node04

​	在持久化的时候，文件的属性会持久化，但文件的每一个块不会持久化，

​	恢复的时候，NN会丢失块的位置信息



​	分布式时代，数据一致性~！！！

​	等：DN会和NN建立心跳，汇报块信息~！！！



# HDFS中的SNN

SecondaryNameNode（SNN）

- 在非HA模式下，SNN一般是一个独立节点，周期完成对NN的EditLog向FsImage合并，减少EditLog大小，减少NN启动时间
- 根据配置文件设置的时间间隔fs.checkpoint.period默认3600秒
- 根据配置文件设置的edits log大小 fs.checkpoint.size规定edits文件的最大值默认是64MB